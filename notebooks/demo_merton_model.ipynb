{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PINN-SGM Demo: Solving Fokker-Planck for Merton Model\n",
    "\n",
    "This notebook demonstrates the complete workflow for:\n",
    "1. Solving the Fokker-Planck equation using PINNs\n",
    "2. Extracting theoretical score functions\n",
    "3. Creating hybrid scores for diffusion models\n",
    "\n",
    "**Author**: Bilal Saleh Husain  \n",
    "**Course**: FM9561 - Special Topics in Mathematical Finance  \n",
    "**Institution**: Western University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Import PINN-SGM components\n",
    "from pinn_sgm.equations import FokkerPlanckMerton\n",
    "from pinn_sgm.solvers import PINNSolver\n",
    "from pinn_sgm.nets import DensityMLP\n",
    "from pinn_sgm.config import MertonModelConfig, PINNConfig, TrainingConfig, ScoreModelConfig\n",
    "from pinn_sgm.utils import ScoreExtractor, hybrid_score\n",
    "from pinn_sgm.utils import plot_density_evolution, plot_score_field, plot_training_history\n",
    "from pinn_sgm.utils import plot_density_heatmap, plot_error_analysis, plot_3d_surface\n",
    "\n",
    "# Configure plotting\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "%matplotlib inline\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Merton Model\n",
    "\n",
    "The Merton structural model assumes firm asset value $V_t$ follows:\n",
    "$$dV_t = \\mu V_t dt + \\sigma V_t dW_t$$\n",
    "\n",
    "In log-space $X_t = \\ln V_t$:\n",
    "$$dX_t = \\alpha dt + \\sigma dW_t, \\quad \\alpha = \\mu - \\frac{\\sigma^2}{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Merton model parameters\n",
    "merton_config = MertonModelConfig(\n",
    "    mu=0.05,       # 5% expected asset return\n",
    "    sigma=0.2,     # 20% asset volatility\n",
    "    x0=0.0,        # Initial log-asset value (V_0 = exp(0) = 1)\n",
    "    debt_threshold=0.8  # Default if V_T < 0.8\n",
    ")\n",
    "\n",
    "print(f\"Merton Model Configuration:\")\n",
    "print(f\"  Asset drift (μ): {merton_config.mu}\")\n",
    "print(f\"  Asset volatility (σ): {merton_config.sigma}\")\n",
    "print(f\"  Effective drift (α): {merton_config.alpha:.6f}\")\n",
    "print(f\"  Initial log-value (X_0): {merton_config.x0}\")\n",
    "print(f\"  Debt threshold (D): {merton_config.debt_threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Fokker-Planck Equation\n",
    "\n",
    "The density $p(x, t)$ satisfies:\n",
    "$$\\frac{\\partial p}{\\partial t} + \\alpha \\frac{\\partial p}{\\partial x} - \\frac{\\sigma^2}{2} \\frac{\\partial^2 p}{\\partial x^2} = 0$$\n",
    "\n",
    "**Analytical Solution** (Gaussian):\n",
    "$$p(x, t) = \\frac{1}{\\sqrt{2\\pi \\sigma^2 t}} \\exp\\left(-\\frac{(x - x_0 - \\alpha t)^2}{2\\sigma^2 t}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Fokker-Planck equation\n",
    "equation = FokkerPlanckMerton(\n",
    "    config=merton_config,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"\\nFokker-Planck Equation: {equation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configure PINN Solver\n",
    "\n",
    "The PINN minimizes:\n",
    "$$\\mathcal{L}(\\theta) = \\mathcal{L}_{\\text{PDE}}(\\theta) + \\mathcal{L}_{\\text{IC}}(\\theta) + \\mathcal{L}_{\\text{norm}}(\\theta)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PINN configuration\n",
    "pinn_config = PINNConfig(\n",
    "    T=1.0,                     # Terminal time\n",
    "    x_min=-5.0,                # Spatial domain\n",
    "    x_max=5.0,\n",
    "    num_collocation=10000,     # Interior points for PDE\n",
    "    num_initial=1000,          # Points for initial condition\n",
    "    num_boundary=0,            # No boundary conditions (unbounded domain)\n",
    "    device=str(device),\n",
    "    enforce_normalization=True,\n",
    "    normalization_weight=1.0\n",
    ")\n",
    "\n",
    "# Training configuration\n",
    "training_config = TrainingConfig(\n",
    "    batch_size=1024,\n",
    "    epochs=5000,\n",
    "    learning_rate=1e-3,\n",
    "    lr_decay_step=1000,\n",
    "    lr_decay_rate=0.9,\n",
    "    optimizer='adam',\n",
    "    gradient_clip_val=1.0,\n",
    "    verbose=True,\n",
    "    log_interval=500\n",
    ")\n",
    "\n",
    "print(f\"PINN Configuration:\")\n",
    "print(f\"  Spatial domain: [{pinn_config.x_min}, {pinn_config.x_max}]\")\n",
    "print(f\"  Time horizon: [0, {pinn_config.T}]\")\n",
    "print(f\"  Collocation points: {pinn_config.num_collocation}\")\n",
    "print(f\"\\nTraining Configuration:\")\n",
    "print(f\"  Epochs: {training_config.epochs}\")\n",
    "print(f\"  Learning rate: {training_config.learning_rate}\")\n",
    "print(f\"  Batch size: {training_config.batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Neural Network\n",
    "\n",
    "We use a `DensityMLP` with Softplus output activation to ensure $p(x, t) > 0$:\n",
    "$$p(x, t) = \\text{Softplus}(\\text{NN}(x, t)) = \\log(1 + e^{z})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create neural network\n",
    "network = DensityMLP(\n",
    "    input_dim=2,              # (x, t)\n",
    "    hidden_dims=[64, 64, 64], # 3 hidden layers with 64 neurons each\n",
    "    activation='tanh',        # Tanh activation for hidden layers\n",
    "    use_softplus=True         # Softplus output for positivity\n",
    ")\n",
    "\n",
    "print(f\"\\nNeural Network Architecture:\")\n",
    "print(network)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in network.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train PINN Solver\n",
    "\n",
    "This cell trains the PINN by minimizing the physics residual and initial condition error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PINN solver\n",
    "solver = PINNSolver(\n",
    "    equation=equation,\n",
    "    network=network,\n",
    "    pinn_config=pinn_config,\n",
    "    training_config=training_config\n",
    ")\n",
    "\n",
    "# Train the PINN\n",
    "print(\"\\nStarting PINN training...\\n\")\n",
    "results = solver.train()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Training completed!\")\n",
    "print(f\"Final total loss: {results['final_loss']:.6e}\")\n",
    "print(f\"Final PDE loss: {solver.history['loss_pde'][-1]:.6e}\")\n",
    "print(f\"Final IC loss: {solver.history['loss_ic'][-1]:.6e}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig = plot_training_history(solver.history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Density Evolution\n",
    "\n",
    "Compare PINN solution with analytical Gaussian solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot density evolution at multiple time points\n",
    "fig = plot_density_evolution(\n",
    "    network=solver.network,\n",
    "    x_range=(-5.0, 5.0),\n",
    "    time_points=[0.1, 0.5, 1.0],\n",
    "    analytical_solution=equation.analytical_solution,\n",
    "    num_points=300,\n",
    "    device=device\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 2D Heatmap Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2D heatmap of density evolution\n",
    "fig = plot_density_heatmap(\n",
    "    network=solver.network,\n",
    "    x_range=(-5.0, 5.0),\n",
    "    t_range=(0.01, 1.0),\n",
    "    num_x_points=200,\n",
    "    num_t_points=100,\n",
    "    device=device\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate error metrics\n",
    "errors = solver.evaluate_error(num_test_points=1000)\n",
    "\n",
    "print(\"\\nError Metrics (vs. Analytical Solution):\")\n",
    "print(f\"  L2 Error: {errors['l2_error']:.6e}\")\n",
    "print(f\"  Max Absolute Error: {errors['max_abs_error']:.6e}\")\n",
    "print(f\"  Mean Absolute Error: {errors['mean_abs_error']:.6e}\")\n",
    "print(f\"  Mean Relative Error: {errors['mean_rel_error']:.6f}\")\n",
    "\n",
    "# Plot error heatmaps\n",
    "fig = plot_error_analysis(\n",
    "    network=solver.network,\n",
    "    analytical_solution=equation.analytical_solution,\n",
    "    x_range=(-5.0, 5.0),\n",
    "    t_range=(0.01, 1.0),\n",
    "    device=device\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Extract Score Function\n",
    "\n",
    "The **score function** is:\n",
    "$$s(x, t) = \\nabla_x \\log p(x, t) = \\frac{\\nabla_x p(x, t)}{p(x, t)}$$\n",
    "\n",
    "For the Gaussian analytical solution:\n",
    "$$s(x, t) = -\\frac{x - (x_0 + \\alpha t)}{\\sigma^2 t}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create score extractor\n",
    "score_extractor = ScoreExtractor(\n",
    "    network=solver.network,\n",
    "    device=device,\n",
    "    epsilon=1e-8\n",
    ")\n",
    "\n",
    "# Compute score at test points\n",
    "x_test = torch.tensor([[-2.0], [0.0], [2.0]], device=device, dtype=torch.float32)\n",
    "t_test = torch.tensor([[0.5], [0.5], [0.5]], device=device, dtype=torch.float32)\n",
    "\n",
    "scores = score_extractor(x_test, t_test)\n",
    "\n",
    "print(\"\\nScore Function Evaluation at t=0.5:\")\n",
    "for i in range(len(x_test)):\n",
    "    print(f\"  s(x={x_test[i].item():.1f}, t=0.5) = {scores[i].item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Visualize Score Field Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot score field at multiple time points\n",
    "fig = plot_score_field(\n",
    "    score_extractor=score_extractor,\n",
    "    x_range=(-5.0, 5.0),\n",
    "    time_points=[0.1, 0.5, 1.0],\n",
    "    num_points=300,\n",
    "    device=device\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Hybrid Score Field\n",
    "\n",
    "Blend empirical score (from data) with theoretical score (from PINN):\n",
    "$$\\hat{s}(x, t) = (1 - \\phi_t) s_\\theta(x, t) + \\phi_t s_{\\text{theory}}(x, t)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure hybrid scoring\n",
    "score_config = ScoreModelConfig(\n",
    "    phi_start=0.0,     # At t=0: use empirical score\n",
    "    phi_end=1.0,       # At t=T: use theoretical score\n",
    "    interpolation='linear'\n",
    ")\n",
    "\n",
    "# Simulate empirical score (in practice, this would be a trained network)\n",
    "def mock_empirical_score(x, t):\n",
    "    \"\"\"Mock empirical score with some noise.\"\"\"\n",
    "    # Add small perturbation to theoretical score\n",
    "    s_theory = score_extractor(x, t)\n",
    "    noise = 0.1 * torch.randn_like(s_theory)\n",
    "    return s_theory + noise\n",
    "\n",
    "# Compute hybrid scores at different times\n",
    "x_grid = torch.linspace(-5, 5, 100, device=device).unsqueeze(-1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for idx, t_val in enumerate([0.1, 0.5, 1.0]):\n",
    "    t_grid = torch.full((100, 1), t_val, device=device)\n",
    "    \n",
    "    # Compute scores\n",
    "    s_empirical = mock_empirical_score(x_grid, t_grid)\n",
    "    s_theoretical = score_extractor(x_grid, t_grid)\n",
    "    s_hybrid = hybrid_score(\n",
    "        x_grid, t_grid,\n",
    "        s_empirical, s_theoretical,\n",
    "        score_config, T=1.0\n",
    "    )\n",
    "    \n",
    "    # Plot\n",
    "    x_np = x_grid.cpu().numpy().flatten()\n",
    "    axes[idx].plot(x_np, s_empirical.cpu().numpy(), 'b--', alpha=0.5, label='Empirical')\n",
    "    axes[idx].plot(x_np, s_theoretical.cpu().numpy(), 'r--', alpha=0.5, label='Theoretical')\n",
    "    axes[idx].plot(x_np, s_hybrid.cpu().numpy(), 'g-', linewidth=2, label='Hybrid')\n",
    "    axes[idx].set_xlabel('x')\n",
    "    axes[idx].set_ylabel('Score')\n",
    "    axes[idx].set_title(f't = {t_val:.1f} (φ = {score_config.get_phi(t_val, 1.0):.2f})')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nHybrid Score Weights:\")\n",
    "for t in [0.0, 0.25, 0.5, 0.75, 1.0]:\n",
    "    phi = score_config.get_phi(t, T=1.0)\n",
    "    print(f\"  t={t:.2f}: φ={phi:.3f} (empirical weight: {1-phi:.3f}, theoretical weight: {phi:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Default Probability Calculation\n",
    "\n",
    "For the Merton model with debt threshold $D$:\n",
    "$$P(\\text{default}) = P(V_T < D) = P(X_T < \\ln D) = \\Phi\\left(\\frac{\\ln D - (x_0 + \\alpha T)}{\\sigma\\sqrt{T}}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute default probability\n",
    "T_horizon = 1.0\n",
    "prob_default = equation.default_probability(t=T_horizon)\n",
    "\n",
    "print(f\"\\nDefault Probability Analysis:\")\n",
    "print(f\"  Time horizon: {T_horizon} year\")\n",
    "print(f\"  Debt threshold: ${merton_config.debt_threshold:.2f}\")\n",
    "print(f\"  Initial asset value: $1.00\")\n",
    "print(f\"  Probability of default: {prob_default*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained PINN model\n",
    "model_path = 'trained_pinn_merton.pth'\n",
    "solver.save(model_path)\n",
    "print(f\"\\nModel saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "1. ✅ Configured the Merton structural credit risk model\n",
    "2. ✅ Defined the Fokker-Planck equation for log-asset dynamics\n",
    "3. ✅ Trained a Physics-Informed Neural Network to solve the PDE\n",
    "4. ✅ Validated against analytical Gaussian solution\n",
    "5. ✅ Extracted theoretical score functions via automatic differentiation\n",
    "6. ✅ Demonstrated hybrid score blending for diffusion models\n",
    "7. ✅ Computed default probabilities\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Integrate with empirical diffusion models trained on market data\n",
    "- Extend to multi-asset portfolios\n",
    "- Apply to option pricing with stochastic volatility\n",
    "- Calibrate to real credit spreads\n",
    "\n",
    "---\n",
    "\n",
    "**References**:\n",
    "- PhD Research Document: Chapters 2-3\n",
    "- Raissi et al. (2019): Physics-Informed Neural Networks\n",
    "- Song et al. (2021): Score-Based Generative Modeling\n",
    "- Merton (1974): On the Pricing of Corporate Debt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
