"""
Fokker-Planck equation implementations for financial models.

This module implements the Fokker-Planck equation (FPE) governing the evolution
of probability density functions for stochastic processes.
"""

from typing import Optional
import torch
import numpy as np

from .base import BasePDE, BaseSDE


class FokkerPlanckMertonND(BasePDE, BaseSDE):
    """
    N-dimensional Fokker-Planck equation for multivariate Merton model.

    The n-dimensional Merton model assumes:
        dX_t = Œº dt + Œ£ dW_t

    where:
        X_t ‚àà ‚Ñù‚Åø: state vector
        Œº ‚àà ‚Ñù‚Åø: constant drift vector
        Œ£ ‚àà ‚Ñù‚ÅøÀ£‚Åø: constant volatility matrix
        W_t ‚àà ‚Ñù‚Åø: n-dimensional Brownian motion

    The probability density p(x, t) satisfies the Fokker-Planck equation:
        ‚àÇp/‚àÇt + Œº¬∑‚àáp - (1/2)‚àë·µ¢‚±º D·µ¢‚±º ‚àÇ¬≤p/‚àÇx·µ¢‚àÇx‚±º = 0

    where D = Œ£Œ£·µÄ is the diffusion matrix.

    For constant coefficients starting from x‚ÇÄ, the analytical solution is:
        p(x, t) = ùí©(x; x‚ÇÄ + Œºt, Dt)

    Args:
        spatial_dim: Dimension of state space (n)
        mu: Drift vector [n] or scalar (broadcasted to all dimensions)
        sigma: Volatility matrix [n, n] or vector [n] (diagonal) or scalar (isotropic)
        x0: Initial state [n] or scalar (broadcasted)
        device: Computation device
        dtype: Tensor data type

    Example:
        >>> # 2D model with diagonal covariance
        >>> equation = FokkerPlanckMertonND(
        ...     spatial_dim=2,
        ...     mu=[0.1, 0.05],
        ...     sigma=[0.2, 0.3],  # diagonal: œÉ‚ÇÅ=0.2, œÉ‚ÇÇ=0.3
        ...     x0=[0.0, 0.0]
        ... )
    """

    def __init__(
        self,
        spatial_dim: int,
        mu: Optional[float | list | np.ndarray] = None,
        sigma: Optional[float | list | np.ndarray] = None,
        x0: Optional[float | list | np.ndarray] = None,
        device: torch.device = torch.device('cpu'),
        dtype: torch.dtype = torch.float32
    ):
        # Explicitly call BasePDE.__init__ to set shared attributes (spatial_dim, device, dtype).
        # BaseSDE has an identical __init__ signature; calling BasePDE is sufficient since
        # both set the same attributes.
        BasePDE.__init__(self, spatial_dim=spatial_dim, device=device, dtype=dtype)

        if spatial_dim < 1:
            raise ValueError(f"spatial_dim must be >= 1, got {spatial_dim}")

        # Process drift vector Œº
        if mu is None:
            mu = 0.0
        if np.isscalar(mu):
            mu = np.full(spatial_dim, mu)
        else:
            mu = np.asarray(mu)
            if mu.shape != (spatial_dim,):
                raise ValueError(f"mu must have shape ({spatial_dim},), got {mu.shape}")

        self.mu = torch.tensor(mu, dtype=dtype, device=device)

        # Process volatility matrix Œ£
        if sigma is None:
            sigma = 1.0
        if np.isscalar(sigma):
            # Isotropic: Œ£ = œÉI
            sigma = np.eye(spatial_dim) * sigma
        else:
            sigma = np.asarray(sigma)
            if sigma.ndim == 1:
                # Diagonal: Œ£ = diag(œÉ)
                if sigma.shape != (spatial_dim,):
                    raise ValueError(f"sigma vector must have shape ({spatial_dim},), got {sigma.shape}")
                sigma = np.diag(sigma)
            elif sigma.ndim == 2:
                # Full matrix
                if sigma.shape != (spatial_dim, spatial_dim):
                    raise ValueError(
                        f"sigma matrix must have shape ({spatial_dim}, {spatial_dim}), got {sigma.shape}"
                    )
            else:
                raise ValueError(f"sigma must be scalar, vector, or matrix, got shape {sigma.shape}")

        self.sigma = torch.tensor(sigma, dtype=dtype, device=device)

        # Compute diffusion matrix D = Œ£Œ£·µÄ
        self.D = torch.matmul(self.sigma, self.sigma.T)

        # Process initial state x‚ÇÄ
        if x0 is None:
            x0 = 0.0
        if np.isscalar(x0):
            x0 = np.full(spatial_dim, x0)
        else:
            x0 = np.asarray(x0)
            if x0.shape != (spatial_dim,):
                raise ValueError(f"x0 must have shape ({spatial_dim},), got {x0.shape}")

        self.x0 = torch.tensor(x0, dtype=dtype, device=device)

    def pde_residual(
        self,
        x: torch.Tensor,
        t: torch.Tensor,
        u: torch.Tensor,
        u_t: torch.Tensor,
        u_x: torch.Tensor,
        u_xx: torch.Tensor
    ) -> torch.Tensor:
        """
        Compute n-dimensional Fokker-Planck PDE residual.

        The n-D FPE:
            ‚àÇp/‚àÇt + Œº¬∑‚àáp - (1/2)‚àë·µ¢‚±º D·µ¢‚±º ‚àÇ¬≤p/‚àÇx·µ¢‚àÇx‚±º = 0

        Args:
            x: Spatial coordinates [Batch, spatial_dim]
            t: Time coordinates [Batch, 1]
            u: Density p(x, t) [Batch, 1]
            u_t: Time derivative ‚àÇp/‚àÇt [Batch, 1]
            u_x: Spatial gradient ‚àáp [Batch, spatial_dim]
            u_xx: Hessian matrix [Batch, spatial_dim, spatial_dim]

        Returns:
            PDE residual [Batch, 1]
        """
        # Drift term: Œº¬∑‚àáp
        # u_x shape: [Batch, spatial_dim]
        # mu shape: [spatial_dim]
        drift_term = torch.sum(self.mu * u_x, dim=-1, keepdim=True)  # [Batch, 1]

        # Diffusion term: (1/2) ‚àë·µ¢‚±º D·µ¢‚±º ‚àÇ¬≤p/‚àÇx·µ¢‚àÇx‚±º
        # u_xx shape: [Batch, spatial_dim, spatial_dim]
        # D shape: [spatial_dim, spatial_dim]
        # Contract: ‚àë·µ¢‚±º D·µ¢‚±º H·µ¢‚±º = Tr(D @ H^T) = Tr(D @ H) (since H is symmetric)
        diffusion_term = torch.einsum('ij,bij->b', self.D, u_xx).unsqueeze(-1)  # [Batch, 1]
        diffusion_term = 0.5 * diffusion_term

        # Residual: ‚àÇp/‚àÇt + Œº¬∑‚àáp - (1/2)‚àë·µ¢‚±º D·µ¢‚±º ‚àÇ¬≤p/‚àÇx·µ¢‚àÇx‚±º
        residual = u_t + drift_term - diffusion_term

        return residual

    def initial_condition(self, x: torch.Tensor) -> torch.Tensor:
        """
        Initial condition: Dirac delta at x‚ÇÄ.

        For numerical stability, we approximate Œ¥(x - x‚ÇÄ) with a narrow Gaussian:
            p(x, 0) ‚âà ùí©(x; x‚ÇÄ, Œµ¬≤I)

        Args:
            x: Spatial coordinates [Batch, spatial_dim]

        Returns:
            Initial density [Batch, 1]
        """
        epsilon = 0.01  # Regularization parameter
        variance = epsilon ** 2

        # Multivariate Gaussian
        diff = x - self.x0  # [Batch, spatial_dim]
        exponent = -0.5 * torch.sum(diff ** 2, dim=-1, keepdim=True) / variance  # [Batch, 1]
        coeff = 1.0 / ((2 * np.pi * variance) ** (self.spatial_dim / 2))
        p0 = coeff * torch.exp(exponent)

        return p0

    def analytical_solution(
        self,
        x: torch.Tensor,
        t: torch.Tensor
    ) -> torch.Tensor:
        """
        Analytical solution: multivariate Gaussian.

        For constant Œº and D, starting from x‚ÇÄ, the solution is:
            p(x, t) = ùí©(x; x‚ÇÄ + Œºt, Dt)

        Args:
            x: Spatial coordinates [Batch, spatial_dim]
            t: Time values [Batch, 1] or [Batch]

        Returns:
            Analytical density [Batch, 1]
        """
        # Ensure proper shapes
        if x.dim() == 1:
            x = x.unsqueeze(0)  # [1, spatial_dim]
        if t.dim() == 1:
            t = t.unsqueeze(-1)  # [Batch, 1]

        # Avoid t=0
        t_clamped = torch.clamp(t, min=1e-6)

        batch_size = x.shape[0]

        # Time-evolved mean and covariance (per-sample)
        mu_t = self.x0 + self.mu * t_clamped  # [Batch, spatial_dim]

        # Compute per-sample covariance: cov_t[b] = D * t[b]
        # Reshape t for proper broadcasting: [Batch, 1] -> [Batch, 1, 1]
        t_expanded = t_clamped.view(batch_size, 1, 1)  # [Batch, 1, 1]
        # Expand D to batch dimension: [spatial_dim, spatial_dim] -> [Batch, spatial_dim, spatial_dim]
        cov_t = self.D.unsqueeze(0) * t_expanded  # [Batch, spatial_dim, spatial_dim]

        # Multivariate Gaussian PDF
        # p(x) = (2œÄ)^(-n/2) |Œ£|^(-1/2) exp(-1/2 (x-Œº)·µÄ Œ£‚Åª¬π (x-Œº))

        diff = x - mu_t  # [Batch, spatial_dim]

        # Compute determinant and inverse of covariance matrix (batched)
        det_cov = torch.linalg.det(cov_t)  # [Batch]
        inv_cov = torch.linalg.inv(cov_t)  # [Batch, spatial_dim, spatial_dim]

        # Mahalanobis distance: (x-Œº)·µÄ Œ£‚Åª¬π (x-Œº) (batched)
        mahal = torch.einsum('bi,bij,bj->b', diff, inv_cov, diff)  # [Batch]

        # Gaussian PDF
        coeff = 1.0 / torch.sqrt((2 * np.pi) ** self.spatial_dim * det_cov)
        p = coeff * torch.exp(-0.5 * mahal)

        return p.unsqueeze(-1)  # [Batch, 1]

    def drift(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:
        """
        Compute drift coefficient f(x, t) = Œº (constant drift).

        Args:
            x: State coordinates [Batch, spatial_dim]
            t: Time values [Batch, 1]

        Returns:
            Drift vector Œº [Batch, spatial_dim]
        """
        batch_size = x.shape[0]
        # Expand constant drift to batch size
        return self.mu.unsqueeze(0).expand(batch_size, -1)

    def diffusion(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:
        """
        Compute diffusion coefficient G(x, t) = Œ£ (constant diffusion).

        Args:
            x: State coordinates [Batch, spatial_dim]
            t: Time values [Batch, 1]

        Returns:
            Diffusion matrix Œ£ [Batch, spatial_dim, spatial_dim]
        """
        batch_size = x.shape[0]
        # Expand constant diffusion to batch size
        return self.sigma.unsqueeze(0).expand(batch_size, -1, -1)

    def is_constant_coefficients(self) -> bool:
        """
        Check if drift and diffusion are constant.

        Returns:
            True (Merton model has constant coefficients)
        """
        return True

    def initial_score(self, x: torch.Tensor, t_epsilon: float = 0.1) -> torch.Tensor:
        """
        Initial score function for n-D Merton model.

        For the Dirac delta initial condition p‚ÇÄ(x) = Œ¥(x - x‚ÇÄ), we evaluate
        the score at a small time t_Œµ to avoid the singularity at t=0.

        At small time, the distribution is approximately Gaussian with mean x‚ÇÄ
        and covariance D¬∑t_Œµ, giving:
            s‚ÇÄ(x) ‚âà s(x, t_Œµ) = -(D¬∑t_Œµ)‚Åª¬π(x - x‚ÇÄ - Œº¬∑t_Œµ)

        Args:
            x: Spatial coordinates [Batch, spatial_dim]
            t_epsilon: Regularization time for Dirac delta (default: 0.1)

        Returns:
            Initial score s‚ÇÄ(x) [Batch, spatial_dim]
        """
        # Ensure proper shape
        if x.dim() == 1:
            x = x.unsqueeze(0)

        batch_size = x.shape[0]

        # Evaluate at small time to regularize Dirac delta
        t_small = torch.full((batch_size, 1), t_epsilon, device=self.device, dtype=self.dtype)

        # Use analytical score at small time
        return self.analytical_score(x, t_small)

    def analytical_score(
        self,
        x: torch.Tensor,
        t: torch.Tensor
    ) -> torch.Tensor:
        """
        Analytical score function for n-D Merton model.

        For the Gaussian density with mean Œº_t = x‚ÇÄ + Œºt and covariance Dt,
        the score function is:
            s(x, t) = ‚àá_x log p(x, t) = -(Dt)‚Åª¬π(x - x‚ÇÄ - Œºt)

        Args:
            x: Spatial coordinates [Batch, spatial_dim]
            t: Time values [Batch, 1] or [Batch]

        Returns:
            Score vectors [Batch, spatial_dim]
        """
        # Ensure proper shapes
        if x.dim() == 1:
            x = x.unsqueeze(0)
        if t.dim() == 1:
            t = t.unsqueeze(-1)

        # Avoid t=0
        t_clamped = torch.clamp(t, min=1e-6)

        batch_size = x.shape[0]

        # Time-evolved mean and covariance (per-sample)
        mu_t = self.x0 + self.mu * t_clamped  # [Batch, spatial_dim]

        # Compute per-sample covariance: cov_t[b] = D * t[b]
        # Reshape t for proper broadcasting: [Batch, 1] -> [Batch, 1, 1]
        t_expanded = t_clamped.view(batch_size, 1, 1)  # [Batch, 1, 1]
        # Expand D to batch dimension: [spatial_dim, spatial_dim] -> [Batch, spatial_dim, spatial_dim]
        cov_t = self.D.unsqueeze(0) * t_expanded  # [Batch, spatial_dim, spatial_dim]

        # Compute inverse covariance (batched)
        inv_cov = torch.linalg.inv(cov_t)  # [Batch, spatial_dim, spatial_dim]

        # Score: s(x, t) = -Œ£‚Åª¬π(x - Œº_t) (batched)
        diff = x - mu_t  # [Batch, spatial_dim]
        score = -torch.einsum('bij,bj->bi', inv_cov, diff)  # [Batch, spatial_dim]

        return score

    def __repr__(self) -> str:
        """String representation."""
        return (
            f"FokkerPlanckMertonND(spatial_dim={self.spatial_dim}, "
            f"Œº={self.mu.cpu().numpy()}, D_shape={self.D.shape})"
        )
